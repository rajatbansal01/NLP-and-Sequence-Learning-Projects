{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "gYvlaY6TOdYb"
   },
   "outputs": [],
   "source": [
    "# makning imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.core.display import HTML\n",
    "from itertools import chain\n",
    "from collections import Counter, defaultdict,namedtuple\n",
    "import collections\n",
    "from pomegranate import State, HiddenMarkovModel, DiscreteDistribution\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_G_R9-fehVBy"
   },
   "source": [
    "Read both the input data files and create two lists each for Words and NER tags. \n",
    "Also, create the NER tags list for start and end token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fhomCH80Og3y",
    "outputId": "c9ed1253-79a5-4fb0-d3dd-9ce701bba163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bailey', 'named', 'Australia', 'captain', 'Starc', 'player', 'of', '2015', 'World', 'Cup', 'Australia', 'won', '2003', '2007', '2015', 'Cups', 'Melbourne', 'Starc', 'Warner', 'knocks', 'etched', 'in', 'memory', '2003', 'SA', '2007', 'WI', '2015', 'Australia', 'were', 'venues', 'Starc', 'Warner', 'Melbourne', 'go', 'as', 'great', 'combination']\n"
     ]
    }
   ],
   "source": [
    "sent = open(\"hmm_train_sentences.txt\", \"r\")\n",
    "sent_list = []\n",
    "for line in sent:\n",
    "    for word in line.split():\n",
    "        sent_list.append(word)\n",
    "sent.close()\n",
    "print(sent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "fF80EeNFO4Ys"
   },
   "outputs": [],
   "source": [
    "tags = open(\"hmm_train_ner.txt\", \"r\")\n",
    "tag_list = []\n",
    "start_NER_list = []\n",
    "end_NER_list = []\n",
    "for line in tags:\n",
    "    start_NER_list.append(line.split()[0])\n",
    "    end_NER_list.append(line.split()[-1])\n",
    "    for tag in line.split():\n",
    "        tag_list.append(tag)\n",
    "tags.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cFSmhI4PMcb",
    "outputId": "80e5ed56-bf0c-4c14-8328-3d03753891e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PER', 'O', 'GEO', 'O', 'PER', 'O', 'O', 'TIM', 'O', 'O', 'GEO', 'O', 'TIM', 'TIM', 'TIM', 'O', 'GEO', 'PER', 'PER', 'O', 'O', 'O', 'O', 'TIM', 'GEO', 'TIM', 'GEO', 'TIM', 'GEO', 'O', 'O', 'PER', 'PER', 'GEO', 'O', 'O', 'O', 'O']\n",
      "['PER', 'PER', 'GEO', 'GEO', 'TIM', 'PER']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(tag_list)\n",
    "print(start_NER_list)\n",
    "print(end_NER_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHz3Aq6ehgyH"
   },
   "source": [
    "Write functions for creating unigram, bigram tokens only for NER tags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "-GgyNFVfTYPp"
   },
   "outputs": [],
   "source": [
    "def unigram_token(sequences):\n",
    "    return Counter(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2S9BF8GOVk1A",
    "outputId": "280f502f-a622-4ad8-a1a8-ce55e94aa6a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'O': 18, 'GEO': 7, 'TIM': 7, 'PER': 6})\n"
     ]
    }
   ],
   "source": [
    "tag_ug = unigram_token(tag_list)\n",
    "print(tag_ug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "ch4y4uiyVojH"
   },
   "outputs": [],
   "source": [
    "def bigram_token(sequences):\n",
    "    d = Counter(sequences)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-DU-2J0qWKXm",
    "outputId": "701e3549-9182-4689-bce1-cc55592e9a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PER', 'O'), ('O', 'GEO'), ('GEO', 'O'), ('O', 'PER'), ('PER', 'O'), ('O', 'O'), ('O', 'TIM'), ('TIM', 'O'), ('O', 'O'), ('O', 'GEO'), ('GEO', 'O'), ('O', 'TIM'), ('TIM', 'TIM'), ('TIM', 'TIM'), ('TIM', 'O'), ('O', 'GEO'), ('GEO', 'PER'), ('PER', 'PER'), ('PER', 'O'), ('O', 'O'), ('O', 'O'), ('O', 'O'), ('O', 'TIM'), ('TIM', 'GEO'), ('GEO', 'TIM'), ('TIM', 'GEO'), ('GEO', 'TIM'), ('TIM', 'GEO'), ('GEO', 'O'), ('O', 'O'), ('O', 'PER'), ('PER', 'PER'), ('PER', 'GEO'), ('GEO', 'O'), ('O', 'O'), ('O', 'O')]\n"
     ]
    }
   ],
   "source": [
    "range_index = [(tag_list[i],tag_list[i+1]) for i in range(0,len(tag_list)-2,1)]\n",
    "print(range_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cCzAkclhWUcz",
    "outputId": "459818d0-5452-4a86-f4ff-121db9dfadfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('O', 'O'): 8, ('GEO', 'O'): 4, ('PER', 'O'): 3, ('O', 'GEO'): 3, ('O', 'TIM'): 3, ('TIM', 'GEO'): 3, ('O', 'PER'): 2, ('TIM', 'O'): 2, ('TIM', 'TIM'): 2, ('PER', 'PER'): 2, ('GEO', 'TIM'): 2, ('GEO', 'PER'): 1, ('PER', 'GEO'): 1})\n"
     ]
    }
   ],
   "source": [
    "tag_count_bg = bigram_token(range_index)\n",
    "print(tag_count_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "83fwJZBuWf7t"
   },
   "outputs": [],
   "source": [
    "def NER_word_count(tag, words):\n",
    "    dDict = defaultdict(lambda: defaultdict(int))\n",
    "    for tag, word in zip(tag_list, sent_list):\n",
    "        dDict[tag][word] += 1\n",
    "        \n",
    "    return dDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0naE3thKhj37"
   },
   "source": [
    "Also, create the NER tags list for start and end token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zUekO8sUXK_5",
    "outputId": "69ed997a-a1aa-4bd6-d8a3-4843f8392683"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.NER_word_count.<locals>.<lambda>>,\n",
       "            {'GEO': defaultdict(int,\n",
       "                         {'Australia': 3, 'Melbourne': 2, 'SA': 1, 'WI': 1}),\n",
       "             'O': defaultdict(int,\n",
       "                         {'Cup': 1,\n",
       "                          'Cups': 1,\n",
       "                          'World': 1,\n",
       "                          'as': 1,\n",
       "                          'captain': 1,\n",
       "                          'combination': 1,\n",
       "                          'etched': 1,\n",
       "                          'go': 1,\n",
       "                          'great': 1,\n",
       "                          'in': 1,\n",
       "                          'knocks': 1,\n",
       "                          'memory': 1,\n",
       "                          'named': 1,\n",
       "                          'of': 1,\n",
       "                          'player': 1,\n",
       "                          'venues': 1,\n",
       "                          'were': 1,\n",
       "                          'won': 1}),\n",
       "             'PER': defaultdict(int, {'Bailey': 1, 'Starc': 3, 'Warner': 2}),\n",
       "             'TIM': defaultdict(int, {'2003': 2, '2007': 2, '2015': 3})})"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NER_words_count=NER_word_count(tag_list,sent_list)\n",
    "NER_words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_f4c_6zZH-c",
    "outputId": "24cc4840-bb3c-43ec-c7bf-f3cf84112168"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'GEO': 2, 'PER': 3, 'TIM': 1})"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_NER_count = Counter(start_NER_list)\n",
    "start_NER_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLWn3QRThymI"
   },
   "source": [
    "Create HiddenMarkovModel (from pomegranate library) to identify entities for words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "Yn3UdGrOXXSi"
   },
   "outputs": [],
   "source": [
    "#Build Hidden Markov Model\n",
    "hmm_model = HiddenMarkovModel(name=\"base-hmm-tagger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fg9QrjpFh10b"
   },
   "source": [
    "b. Calculate the start, end, and emission probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "e3vm9ni-Yhc8"
   },
   "outputs": [],
   "source": [
    "# Calculate start probability\n",
    "hmm_model.add_states()\n",
    "start_prob={}\n",
    "for ps in tag_list:\n",
    "    start_prob[ps]=start_NER_count[ps]/tag_ug[ps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SlnUsFdIZyJs",
    "outputId": "c33ed4a2-6e88-4209-ff6b-4627ad504113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PER': 0.5, 'O': 0.0, 'GEO': 0.2857142857142857, 'TIM': 0.14285714285714285}\n"
     ]
    }
   ],
   "source": [
    "print(start_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "3a_Wq2u8bin8"
   },
   "outputs": [],
   "source": [
    "#Arrive at Emission probabilties \n",
    "to_states = []\n",
    "for NER, words in NER_words_count.items():\n",
    "    total = float(sum(words.values()))\n",
    "    distribution = {word: count/total for word, count in words.items()}\n",
    "    NER_emissions = DiscreteDistribution(distribution)\n",
    "    NER_state = State(NER_emissions, name=NER)\n",
    "    to_states.append(NER_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "-d-m75J5aNGj"
   },
   "outputs": [],
   "source": [
    "## Calculate end probability\n",
    "end_NER_count = Counter(end_NER_list)\n",
    "for NER_state in to_states :\n",
    "    hmm_model.add_transition(hmm_model.start,NER_state,start_prob[NER_state.name])\n",
    "end_prob={}\n",
    "\n",
    "for ps in tag_list:\n",
    "    end_prob[ps]=end_NER_count[ps]/tag_ug[ps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4poixnMybHg5",
    "outputId": "e19415af-8036-45e8-afae-b398bf18f219"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GEO': 0.0, 'O': 0.3333333333333333, 'PER': 0.0, 'TIM': 0.0}"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYlBIGfviQyK"
   },
   "source": [
    "Calculate the transitional probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "v4tfc3CNfHW8"
   },
   "outputs": [],
   "source": [
    "# Add transition states to the HMM model\n",
    "for NER_state in to_states :\n",
    "    hmm_model.add_transition(NER_state,hmm_model.end,end_prob[NER_state.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "AsfkDYcMchaP"
   },
   "outputs": [],
   "source": [
    "# Get the transitional probability \n",
    "transition_prob_NER_word={}\n",
    "for key in tag_count_bg.keys():\n",
    "    transition_prob_NER_word[key]=tag_count_bg.get(key)/tag_ug[key[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1PlfKXVxcvXF",
    "outputId": "d35d8457-b0d2-4791-de35-dbcf12ae26f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('GEO', 'O'): 0.5714285714285714,\n",
       " ('GEO', 'PER'): 0.14285714285714285,\n",
       " ('GEO', 'TIM'): 0.2857142857142857,\n",
       " ('O', 'GEO'): 0.16666666666666666,\n",
       " ('O', 'O'): 0.4444444444444444,\n",
       " ('O', 'PER'): 0.1111111111111111,\n",
       " ('O', 'TIM'): 0.16666666666666666,\n",
       " ('PER', 'GEO'): 0.16666666666666666,\n",
       " ('PER', 'O'): 0.5,\n",
       " ('PER', 'PER'): 0.3333333333333333,\n",
       " ('TIM', 'GEO'): 0.42857142857142855,\n",
       " ('TIM', 'O'): 0.2857142857142857,\n",
       " ('TIM', 'TIM'): 0.2857142857142857}"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_prob_NER_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "2WefY9cZf4a3"
   },
   "outputs": [],
   "source": [
    "# Add transition probabilities to all POS\n",
    "transition_prob_NER_word[('PER', 'TIM')]=0\n",
    "transition_prob_NER_word[('GEO', 'GEO')]=0\n",
    "transition_prob_NER_word[('TIM', 'PER')]=0\n",
    "\n",
    "for NER_state in to_states :\n",
    "    for next_NER_state in to_states :\n",
    "        hmm_model.add_transition(NER_state,next_NER_state,transition_prob_NER_word[(NER_state.name,next_NER_state.name)])\n",
    "hmm_model.bake()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTIor4_uiUtN"
   },
   "source": [
    "d. Predict entities for this sentence, â€œStarc named 2015 Australia player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "E8ktnWJVdIln"
   },
   "outputs": [],
   "source": [
    "# Decode NER for a new sentence\n",
    "def NER_decoding(sentence, model):\n",
    "    \n",
    "    _, state_path = model.viterbi(sentence)\n",
    "    return [state[1].name for state in state_path[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "reterfokdrAl"
   },
   "outputs": [],
   "source": [
    "NER_tags = NER_decoding((\"Starc\", \"named\", \"2015\" ,\"Australia\",\"player\"), hmm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "GPgUx_0GdvTN",
    "outputId": "e74d7231-7451-4d4c-aa9c-75dfc8f28de6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"['PER', 'O', 'TIM', 'GEO', 'O']\""
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(NER_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ztZ6dqHDgzDQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ipynb1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
